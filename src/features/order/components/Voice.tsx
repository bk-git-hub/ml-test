import { useEffect, useState, useRef } from 'react';
import SpeechRecognition, {
  useSpeechRecognition,
} from 'react-speech-recognition';
import { useChatStore } from '@/features/chat/store/chatStore';
import { useVoiceStore } from '../store/voiceStore';
import LanguageSelector from '@/components/LanguageSelector';
import { useGpt } from '../hooks/useGpt';
import { useLanguageStore } from '@/store/languageStore';

const apiUrl = import.meta.env.VITE_GPT_API_URL;

const Voice = () => {
  const { listening, transcript, resetTranscript } = useSpeechRecognition();
  const { isCovered, setIsCovered } = useVoiceStore();
  const [detectedCount, setDetectedCount] = useState(0);
  const [isProcessing, setIsProcessing] = useState(false);
  const [capturedText, setCapturedText] = useState('');
  const lastTextTimeRef = useRef<number>(0);
  const keywordIndexRef = useRef<number>(-1);
  const detectedKeywordRef = useRef<string | null>(null);

  const { language } = useLanguageStore();
  const langCode = language === 'en' ? 'en-US' : 'ko-KR';

  // ì—¬ëŸ¬ í‚¤ì›Œë“œ ë°°ì—´
  const KEYWORDS = language === 'en'
    ? ['malang', 'hello', 'start']  // ì˜ì–´ í‚¤ì›Œë“œ ì˜ˆì‹œ//////////////////////////////////////////ì¶”ê°€ ê°€ëŠ¥
    : ['ë§ë‘ì•„', 'ë¹¨ë‘ì•„', 'ë¹¨ë‘ ì™€'];     // í•œêµ­ì–´ í‚¤ì›Œë“œ ì˜ˆì‹œ

  const addMessage = useChatStore((state) => state.addMessage);
  const updateLastMessage = useChatStore((state) => state.updateLastMessage);
  const setIsCapturing = useChatStore((state) => state.setIsCapturing);
  const isCapturing = useChatStore((state) => state.isCapturing);
  const { sendTextToApi } = useGpt({ apiUrl });

  // ğŸ§  ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ê°ì§€
  useEffect(() => {
    if (transcript) {
      lastTextTimeRef.current = Date.now();

      if (isCapturing && keywordIndexRef.current !== -1 && detectedKeywordRef.current) {
        const textAfterKeyword = transcript
          .slice(keywordIndexRef.current + detectedKeywordRef.current.length)
          .trim();
        setCapturedText(textAfterKeyword);
        updateLastMessage(textAfterKeyword);
      }
    }
  }, [transcript, isCapturing, updateLastMessage]);

  // ğŸ” ì¼ì • ì‹œê°„ í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ ì¸ì‹ ì¢…ë£Œ ë° ì²˜ë¦¬
  useEffect(() => {
    if (!isCapturing) return;

    const checkInterval = setInterval(() => {
      const now = Date.now();
      if (now - lastTextTimeRef.current > 2000) {
        setIsCapturing(false);
        setIsProcessing(false);

        if (capturedText) {
          sendTextToApi(capturedText).catch((err) => {
            console.error('Error processing voice input:', err);
          });
        }

        resetTranscript();
        keywordIndexRef.current = -1;
        detectedKeywordRef.current = null;
        setCapturedText('');
      }
    }, 100);

    return () => clearInterval(checkInterval);
  }, [isCapturing, capturedText, sendTextToApi]);

  // ğŸ¯ í‚¤ì›Œë“œ ê°ì§€ (ì—¬ëŸ¬ í‚¤ì›Œë“œ ì¤‘ ì²« ë°œê²¬ëœ í‚¤ì›Œë“œ ì„ íƒ)
  useEffect(() => {
    if (!transcript || isProcessing) return;

    let foundKeyword: string | null = null;
    let foundIndex = -1;

    for (const keyword of KEYWORDS) {
      const idx = transcript.indexOf(keyword);
      if (idx !== -1) {
        foundKeyword = keyword;
        foundIndex = idx;
        break; // ì²« ë°œê²¬ í‚¤ì›Œë“œë§Œ ì²˜ë¦¬
      }
    }

    if (foundKeyword && keywordIndexRef.current === -1) {
      setIsProcessing(true);
      setDetectedCount((prev) => prev + 1);
      setIsCapturing(true);
      setCapturedText('');
      lastTextTimeRef.current = Date.now();
      keywordIndexRef.current = foundIndex;
      detectedKeywordRef.current = foundKeyword;

      addMessage({
        text: '',
        isUser: true,
        timestamp: Date.now(),
      });
    }
  }, [transcript, isProcessing, KEYWORDS]);

  // âœ… ì–¸ì–´ ë³€ê²½ ë˜ëŠ” ë®ê°œ í•´ì œ ì‹œ ë§ˆì´í¬ ì¬ì‹œì‘ ê°•ì œ ë³´ì¥ + ë””ë²„ê¹… ë¡œê·¸
  useEffect(() => {
    const tryStartListening = async () => {
      console.log('ğŸ¤ Restarting listening...');
      await SpeechRecognition.stopListening();
      setTimeout(() => {
        SpeechRecognition.startListening({
          continuous: true,
          language: langCode,
        });
        setTimeout(() => {
          console.log('ğŸ§ listening (delayed):', listening);
          console.log('ğŸ—£ï¸ transcript (delayed):', transcript);
        }, 1000);
      }, 300);
    };

    if (!isCovered && !listening) {
      tryStartListening();
    }
  }, [language, isCovered, listening, langCode, transcript]);

  // ğŸ”‡ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë§ˆì´í¬ ì •ì§€
  useEffect(() => {
    return () => {
      SpeechRecognition.stopListening();
    };
  }, []);

  // ğŸ§ listening ìƒíƒœ, transcript ì‹¤ì‹œê°„ ë¡œê·¸ (ë””ë²„ê¹…ìš©)
  useEffect(() => {
    console.log('ğŸ§ listening ìƒíƒœ:', listening);
    console.log('ğŸ—£ï¸ transcript:', transcript);
  }, [listening, transcript]);

  useEffect(() => {
    const restartListening = async () => {
      try {
        console.log('â–¶ï¸ Restarting listening due to language/isCovered change...');
        await SpeechRecognition.stopListening();
        // 0.3ì´ˆ ê¸°ë‹¤ë ¸ë‹¤ê°€ ì‹œì‘ (ë§ˆì´í¬ê°€ ì™„ì „íˆ ë©ˆì¶”ë„ë¡)
        await new Promise((resolve) => setTimeout(resolve, 300));
        await SpeechRecognition.startListening({
          continuous: true,
          language: langCode,
        });
        console.log('â–¶ï¸ Started listening with language:', langCode);
      } catch (error) {
        console.error('Error restarting listening:', error);
      }
    };

    if (!isCovered) {
      restartListening();
    }
  }, [language, isCovered, langCode]);

  return (
    <div className='p-6 h-fit rounded-xl shadow-lg bg-white text-center'>
      {isCovered && (
        <div
          className="
            absolute top-0 left-0 w-screen h-screen p-6
            flex flex-col items-center justify-center
            cursor-pointer
            bg-white/80
            border-4 border-indigo-500
            rounded-none
            shadow-xl
            backdrop-blur-md
          "
          onClick={() => {
            setIsCovered(false);
            setTimeout(() => {
              SpeechRecognition.startListening({
                continuous: true,
                language: langCode,
              });
            }, 200);
          }}
        >
          <div className="absolute top-6 left-6 text-2xl font-bold text-indigo-600 select-none drop-shadow-md">
            Mallang Order
          </div>

          {/* âœ… í•œ/ì˜ ì „í™˜ ë²„íŠ¼ */}
          <div className="absolute top-6 right-6">
            <button
              onClick={(e) => {
                e.stopPropagation(); // ğŸ’¥ prevent parent div click
                useLanguageStore.setState((state) => ({
                  language: state.language === 'en' ? 'ko' : 'en',
                }));
              }}
              className="px-4 py-2 rounded-lg bg-indigo-600 text-white font-semibold shadow hover:bg-indigo-700 transition"
            >
              {language === 'en' ? 'í•œê¸€' : 'ENG'}
            </button>
          </div>

          <img
            src="/logoT.png"
            alt="ë§ë‘ ë¡œê³ "
            width={300}
            height={300}
            className="mb-10 rounded-lg shadow-lg"
          />

          <p className="text-[2.5rem] sm:text-4xl md:text-5xl font-bold text-indigo-600 text-center animate-pulse select-none leading-tight whitespace-pre-line">
            {language === 'en'
              ? 'Touch the screen\nto start your order'
              : 'í™”ë©´ì„ í„°ì¹˜í•´\nì£¼ë¬¸ì„ ì‹œì‘í•˜ì„¸ìš”'}
          </p>
        </div>
      )}



      <div className="flex flex-col items-center">
              <p className="text-sm text-indigo-600">
                {listening
                  ? language === 'en'
                    ? <>Listening for<br />the keywordâ€¦</>
                    : <>í‚¤ì›Œë“œ ë§ë‘ì•„<br />ê°ì§€ì¤‘â€¦</>
                  : language === 'en'
                  ? 'Waitingâ€¦'
                  : 'ëŒ€ê¸° ì¤‘â€¦'}
              </p>
            </div>

            {isCapturing && (
              <div className="bg-indigo-100 rounded-lg border border-indigo-300 p-2 mt-2 shadow-sm">
                <p className="text-sm text-indigo-900 mb-1">
                  {language === 'en' ? 'Recognizing speechâ€¦' : 'ìŒì„± ì¸ì‹ ì¤‘â€¦'}
                </p>
              </div>
            )}

    </div>
  );
};

export default Voice;
